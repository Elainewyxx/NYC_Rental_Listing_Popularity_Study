{"cells":[{"metadata":{"_uuid":"2e2c1d77a3f52f68d1329cfb8acd7b9c76932709"},"cell_type":"raw","source":""},{"metadata":{"_uuid":"d90019d3145efdf451510be9cb8a26dd5ea83acd"},"cell_type":"markdown","source":"## Data Import"},{"metadata":{"trusted":true,"_uuid":"828d1ddf2e18baf4b6c2333b49b585f2693d57d5"},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1a623cb84455f8648f9e59b7da1f8ed31441a4cb","_kg_hide-input":false,"_kg_hide-output":false},"cell_type":"code","source":"import json\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn import preprocessing\nimport warnings  \nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5bafa7febbf212b638bd0c4949b6ac78a8215c6e"},"cell_type":"code","source":"df_original = pd.read_json('../input/train.json')\ndf = df_original.copy()\ndf.index = df['listing_id']\ndf = df.drop('listing_id',1)\ndf['interest_level'] = df['interest_level'].map({'medium':0, 'low' : -1, 'high': 1})\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ee381147bb49889e76487c5ebdb30ac97dc226c1"},"cell_type":"markdown","source":"## Data Cleaning\n-  __Drop: created, display_address, street_address, latitude, longtitude__\n"},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"9cd04c0bc5db446acdc34328b7da723c59169c75"},"cell_type":"code","source":"df = df.drop(['created', 'display_address', 'street_address', 'latitude', 'longitude'], 1)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b8d2b763384f8ef96a0460fc749bf57e3fae9adf"},"cell_type":"markdown","source":"- __latitude, longtitude, price, bedroom, description__"},{"metadata":{"trusted":true,"_uuid":"f8f6cb6f7a15313708cbc75827abdd0112bbde57"},"cell_type":"code","source":"def price_beds(df):\n    '''For bedroom and price, build price/bedrooms and drop the two columns.'''\n    beds = np.array(df['bedrooms'])\n    beds += 1\n    price = np.array(df['price'])\n    p_b = price/beds\n    df['price/bedrooms'] = p_b\n    df['price/bedrooms'] = preprocessing.scale(df['price/bedrooms'])\n    df = df.drop('bedrooms', 1)\n    df = df.drop('price', 1)\n    return df\n\ndef des_length(df):\n    '''For description, change the column into the length of the description.'''\n    des_len = []\n    for i in df['description']:\n        des_len.append(len(i))\n    df['des_length'] = des_len\n    df['des_length'] = preprocessing.scale(df['des_length'])\n    df = df.drop('description', 1)\n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4d8adf47389eb78bb988b735404639f7c338187d"},"cell_type":"code","source":"df = des_length(df)\ndf = price_beds(df)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e46edfdbe880f54642cf115bd32f178c4262b4e5"},"cell_type":"markdown","source":"- __photos__"},{"metadata":{"trusted":true,"_uuid":"d7a6cd6ddceba5d491cbf60a1b88eb3be5914f76"},"cell_type":"code","source":"df['Photo Number'] = df['photos'].apply(len)\ndf = df.drop('photos',1)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"49f345e6e01f21af489f94948f968c9b72467d85"},"cell_type":"markdown","source":"- __features__"},{"metadata":{"trusted":true,"_uuid":"445eee27858e5dbb341226cdad6996aa247bfe08"},"cell_type":"code","source":"import string\ntable = str.maketrans('','',string.punctuation)\n#Building a cleaned list and a merged cleaned string for the features column of each instance\ndf['Features List'] = df['features'].apply(lambda y : list(map(lambda x: x.upper().translate(table), y)))\ndf['Features String'] = df['Features List'].apply(' '.join)\ndf = df.drop('features',1)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c3d220f9941585ecaa20fda9f0d105f84afa96e4","_kg_hide-output":false,"_kg_hide-input":false},"cell_type":"code","source":"#Build 24 feature columns containing 0 which occur most frequently. \nfeature = []\nbiglist = []\nfor i in range(len(df)):\n    biglist += df.iloc[i]['Features List']\n    for w in df.iloc[i]['Features List']:\n        if w not in feature:\n            feature.append(w)\nbigdic = {i : biglist.count(i) for i in feature}\n\ndf_feature_count = pd.DataFrame(bigdic, index = ['Count']).T\nadd_ones = list(df_feature_count.sort_values(by = ['Count'],ascending = False)[:24].index)\nfor i in add_ones:\n    df['f_' + '_'.join(i.split(' '))] = 0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8d0c5517c57c3a312b768b84622cf20c1dec0f58"},"cell_type":"code","source":"#Change zeros into binary\nfor i in add_ones:\n    onelist = []\n    for w in range(len(df)):\n        onelist.append(i in df.iloc[w]['Features String'])\n    print('f_' + '_'.join(i.split(' ')))\n    df['f_' + '_'.join(i.split(' '))] = onelist","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2ee5398a52ee67850e427dde1e4d89ab049fdca8","scrolled":true},"cell_type":"code","source":"df = df.drop('Features List', 1)\ndf = df.drop('Features String', 1)\nall_features = df.columns.tolist()\nall_features.remove('interest_level')\nall_features = all_features + ['interest_level']\ndf = df[all_features]\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b5e9d8287f3a3a04c5ba680eb476401145c37184"},"cell_type":"markdown","source":"- __bathrooms, features normalization__"},{"metadata":{"trusted":true,"_uuid":"876619859d696ed482d3dbce9b9b4a16c5b55eaa"},"cell_type":"code","source":"norm_list = ['f_' + '_'.join(i.split(' ')) for i in add_ones] + ['bathrooms','Photo Number']\nfor i in norm_list:\n    df[i] = preprocessing.scale(df[i])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"66c441fd4b52f0e9feb7b1cb61460830a2d0147d"},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ba88a1288822bf4441e239cff43b1baa64287e60"},"cell_type":"markdown","source":"- __manager expected level, building expected level（after train test split）__"},{"metadata":{"trusted":true,"_uuid":"87bf3acc2caae68a2fccbf44a41f2e7f27341d87"},"cell_type":"code","source":"def manager_building_level(x_train, x_test):    \n    \n    gb_m = x_train.groupby(x_train['manager_id'])\n    m_dic = {m_id : np.mean(gb_m.get_group(m_id)['interest_level']) for m_id in gb_m.groups.keys()}\n    x_train['manager_level'] = [m_dic[i] for i in x_train['manager_id']]\n    x_test['manager_level'] = [m_dic[i] if i in gb_m.groups.keys() else np.mean(x_train['interest_level']) for i in x_test['manager_id']]\n    \n    \n    gb_b = x_train.groupby(x_train['building_id'])\n    b_dic = {b_id : np.mean(gb_b.get_group(b_id)['interest_level']) for b_id in gb_b.groups.keys()}\n    x_train['building_level'] = [b_dic[i] for i in x_train['building_id']]\n    x_test['building_level'] = [b_dic[i] if i in gb_b.groups.keys() else np.mean(x_train['interest_level']) for i in x_test['building_id']]\n    \n    \n    x_train = x_train.drop({'manager_id', 'interest_level','building_id'}, 1)\n    x_test = x_test.drop({'manager_id', 'interest_level','building_id'}, 1)\n\n    \n    return x_train, x_test","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"eec0a219a6279108ceed518f0a4c3f698f77cf7e"},"cell_type":"markdown","source":"- __Train Test Split__"},{"metadata":{"trusted":true,"_uuid":"358bf8c0a5f1d05f0c9df5cadd6c46ead06f3d43","scrolled":true,"_kg_hide-output":false},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nx = df\ny = df['interest_level']\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.33)\n\nx_train, x_test = manager_building_level(x_train, x_test) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8807dd594b711cd18d742d6cbb5b20b1c5b1effb"},"cell_type":"code","source":"x_train.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5f0a54137938b8f5f690a63b309a14be9ee9b013"},"cell_type":"markdown","source":"## Model Selection"},{"metadata":{"trusted":true,"_uuid":"9655c29c4b7bc8eddbc178d04e5d7a06e8820ff6"},"cell_type":"code","source":"#Model\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\n\n#Evaluation\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import log_loss\nfrom sklearn.metrics import auc\nfrom sklearn import metrics\nfrom sklearn.model_selection import KFold","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"12e1e515bf1bad8b54695512b0c7d522c2c0c82c"},"cell_type":"markdown","source":"### Linear Regression"},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"2d1f5707a48e2d7a5ccc924cd45fb597132e6f0f"},"cell_type":"code","source":"parameters = [100, 1]\nscores = []\nc_range = [0.0001, 0.001, 0.0025, 0.005, 0.01, 0.05, 0.1, 1]\nfor c in c_range:\n    kf = KFold(n_splits = 3, shuffle = True)\n    score = []\n    for train_index, test_index in kf.split(x):\n        x_train, x_test = x.iloc[train_index, :], x.iloc[test_index, :]\n        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n        \n        x_train, x_test = manager_building_level(x_train, x_test)\n            \n        lr = LogisticRegression(C = c, multi_class='multinomial', solver='lbfgs').fit(x_train, y_train)\n        pred_proba = lr.predict_proba(x_test)\n        score.append(log_loss(y_test, pred_proba))\n        \n    mean_score = sum(score)/len(score)\n    scores.append(mean_score)\n    if mean_score < parameters[0]:\n        parameters = [mean_score, c]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2cf866f2a7e3e8b86b85dcd81b694ca9d42606b3"},"cell_type":"code","source":"plt.plot(np.arange(8), scores)\nplt.xticks(np.arange(8), c_range)\nplt.xlabel(\"C\")\nplt.ylabel(\"Log loss\")\nplt.title(\"Tuning the Regularization for Logistic Regression\")\nplt.annotate('Best C=0.0025',xy=(2,parameters[0]), xytext=(2.5,0.677),\n             arrowprops=dict(facecolor='red'))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a61922a935aa537c9ac473a087cb43856c59b4b8"},"cell_type":"markdown","source":"### K Nearest Neighbor(KNN) Classifier"},{"metadata":{"trusted":true,"_uuid":"d1a646cabbe252ccd469584c2233b08633e67a84"},"cell_type":"code","source":"result_log = pd.DataFrame(np.zeros((6,7)))\nresult_log.index = ['euclidean','manhattan','minkowski','euclidean_w','manhattan_w','minkowski_w']\nresult_log.columns = [50, 100, 150, 200, 250, 300, 350]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"59bee984cd42e2969920842cc621ea50138ab434","scrolled":true},"cell_type":"code","source":"fig = plt.figure(figsize = (10, 8))\nfor i in [50, 100, 150, 200, 250, 300, 350]:\n    print(i)\n    for w in ['euclidean','manhattan','minkowski']:\n        \n        kf = KFold(n_splits = 3, shuffle = True)\n        score = []\n        score_w = []\n        for train_index, test_index in kf.split(x):\n            x_train, x_test = x.iloc[train_index, :], x.iloc[test_index, :]\n            y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n\n            x_train, x_test = manager_building_level(x_train, x_test)\n\n            KNN = KNeighborsClassifier(n_neighbors  = i, weights = 'uniform', metric = w).fit(x_train, y_train)\n            KNN_w = KNeighborsClassifier(n_neighbors  = i, weights = 'distance', metric = w).fit(x_train, y_train)\n            pred_proba_KNN = KNN.predict_proba(x_test)\n            pred_proba_KNN_w = KNN_w.predict_proba(x_test)\n            \n            score.append(log_loss(y_test, pred_proba_KNN))\n            score_w.append(log_loss(y_test, pred_proba_KNN_w))\n\n            mean_score = sum(score)/len(score)\n            mean_score_w = sum(score_w)/len(score_w)\n            \n            result_log.loc[w,i] = mean_score\n            result_log.loc[w+'_w',i] = mean_score_w","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5777581aeeb98bc19ea39a130cf033e422569e66","scrolled":false},"cell_type":"code","source":"result_log","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"92e0d0c0912fe75abc9131ee96720908d53540fb"},"cell_type":"code","source":"fig = plt.figure(figsize = (10, 8))\nfor i in result_log.index:\n    plt.plot([50, 100, 150, 200, 250, 300, 350], result_log.loc[i,:], label = i)\nplt.legend()\nplt.title('Log Loss',fontdict = {'fontsize': 15})\nplt.xlabel('K')\nplt.ylabel('Log Loss')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ca75e646a05c577d5a2b34e7738835d757a798a9"},"cell_type":"markdown","source":"## Random Forest"},{"metadata":{"trusted":true,"_uuid":"43e1d907a9da4b43815e692db29daed794657e6c"},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cc9abf8a308e0c0525f90ac994784837891f79d4"},"cell_type":"code","source":"n_estimators_ =  [200, 400, 600]\nmax_depth_ =  [7,8,9]\nmin_samples_split_ = [100, 150, 200]\nmin_samples_leaf_ = [25, 50, 75]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6ed28e994b0e6d5c2b2df6cfd70498bc2127fc4c"},"cell_type":"code","source":"result = []\nfig = plt.figure(figsize = (10, 8))\nfor est in n_estimators_:\n    print(est)\n    for dep in max_depth_:\n        for spl in min_samples_split_:\n            for lea in min_samples_leaf_:\n                \n                kf = KFold(n_splits = 3, shuffle = True)\n                score = []\n                for train_index, test_index in kf.split(x):\n                    x_train, x_test = x.iloc[train_index, :], x.iloc[test_index, :]\n                    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n                    x_train, x_test = manager_building_level(x_train, x_test)\n\n                    RF = RandomForestClassifier(n_estimators=est, max_depth = dep, min_samples_split = spl, min_samples_leaf = lea, criterion = 'entropy').fit(x_train, y_train)\n                    \n                    pred_proba_RF = RF.predict_proba(x_test)\n                    score.append(log_loss(y_test, pred_proba_RF))\n                mean_score = sum(score)/len(score)\n                result.append(mean_score)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7ab22b22b07eb010b9fee30d9bfee36d32f43efc"},"cell_type":"code","source":"index = ['200_7','200_8','200_9','400_7','400_8','400_9','600_7','600_8','600_9']\ncolumns = ['100_25','100_50','100_75','150_25','150_50','150_75','200_25','200_50','200_75']\naray_log = np.array(result).reshape(9,9)\ndf_log = pd.DataFrame(np.array(result).reshape(9,9))\ndf_log.index = index\ndf_log.columns = columns\ndf_log","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1e9ff490479cc1c2027f2e3cafc4d45a2ec852d6"},"cell_type":"code","source":"fig = plt.figure(figsize=(20,10))\nax1 = plt.subplot(121)\nim1 = ax1.imshow(aray_log)\ncbar = ax1.figure.colorbar(im1, ax=ax1)\nax1.set_xticks(np.arange(9))\nax1.set_yticks(np.arange(9))\nax1.set_xticklabels(['100_25','100_50','100_75','150_25','150_50','150_75','200_25','200_50','200_75'], fontsize=9)\nax1.set_yticklabels(['200_7','200_8','200_9','400_7','400_8','400_9','600_7','600_8','600_9'], fontsize=13)\nfor i in range(9):\n    for j in range(9):\n        text = ax1.text(j, i, round(aray_log[i][j], 4), ha=\"center\", va=\"center\", color=\"w\")\nax1.set_xlabel('min_split/min_leaf', fontsize=16)\nax1.set_ylabel('n_estimaters/max depth', fontsize=16)\nax1.set_title('Log Loss for Random Forest Grid Search', fontsize=16)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"596e402e895885673eaa640dffb6290ce244ef6a"},"cell_type":"code","source":"x = df\ny = df['interest_level']\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.33)\n\nx_train, x_test = manager_building_level(x_train, x_test) \nx_train.head()\n\nlr = LogisticRegression(C = 0.0025, multi_class='multinomial', solver='lbfgs')\nlr.fit(x_train, y_train)\npreds = lr.predict_proba(x_test)\nprint('log_loss of LR (test): %.4f' % log_loss(y_test, preds))\npreds_train = lr.predict_proba(x_train)\nprint('log_loss of LR (train): %.4f' % log_loss(y_train, preds_train))\nprint()\n\nrf = RandomForestClassifier(n_estimators=400,max_depth=9, min_samples_split=100,min_samples_leaf=25,criterion='entropy')\nrf.fit(x_train, y_train)\npreds = rf.predict_proba(x_test)\nprint('log_loss of RF (test): %.4f' % log_loss(y_test, preds))\npreds_train = rf.predict_proba(x_train)\nprint('log_loss of RF (train): %.4f' % log_loss(y_train, preds_train))\nprint()\n\nknn = KNeighborsClassifier(n_neighbors  = 130, metric = 'manhattan')\nknn.fit(x_train, y_train)\npreds = knn.predict_proba(x_test)\nprint('log_loss of kNN (test): %.4f' % log_loss(y_test, preds))\npreds_train = knn.predict_proba(x_train)\nprint('log_loss of kNN (train): %.4f' % log_loss(y_train, preds_train))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"297f3e6fdab758fca021bd05a40e9542dc992b18"},"cell_type":"markdown","source":"## Graphs at Data Cleaning"},{"metadata":{"trusted":true,"scrolled":false,"_uuid":"4668100e10bedd6cc6f8264969642e8937eadf10"},"cell_type":"code","source":"fig = plt.figure(figsize = (8, 6))\n    \nlow = sum(df_original['interest_level'] == 'low')\nmedium = sum(df_original['interest_level'] == 'medium')\nhigh = sum(df_original['interest_level'] == 'high')\ncount = [low, medium, high]\nbars = plt.bar( [1,2,3],count, width = 0.4)\na = 0\nfor bar in bars:\n    num = count[a]/(sum(count))\n    plt.gca().text(bar.get_x() + bar.get_width()/2, bar.get_height() -1500, str(format(num*100,'.2f')) + '%', \n             ha='center', color='w', fontsize=13)\n    a += 1\nplt.xticks([1,2,3], ['Low','Medium','High'], fontsize = 13)\nplt.title('Distribution of Target Variable', fontsize = 15)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b0b4d1d2f070b496d3906b41abc32fe98752e2a1"},"cell_type":"code","source":"fig = plt.figure(figsize = (10, 8))\n\ndf_original['created'] = pd.to_datetime(df_original['created'], format = '%Y-%m-%d %H:%M:%S')\n\nbarwidth = 0.3\nfor i in [4,5,6]:\n    \n    low = sum(df_original[df_original['created'].dt.month == i]['interest_level'] == 'low')\n    medium = sum(df_original[df_original['created'].dt.month == i]['interest_level'] == 'medium')\n    high = sum(df_original[df_original['created'].dt.month == i]['interest_level'] == 'high')\n    count = [low,medium,high]\n    bars = plt.bar([w + (i-5)*barwidth for w in [1,2,3]],count,width = barwidth, label = '2016.'+str(i))\n    a = 0\n    for bar in bars:\n        num = count[a]/(sum(count))\n        plt.gca().text(bar.get_x() + bar.get_width()/2, bar.get_height() - 400, str(format(num*100,'.2f')) + '%', \n                 ha='center', color='w', fontsize=12)\n        a += 1\n    \n    \nplt.xticks([1,2,3], ['Low','Medium','High'])\nplt.legend()\nplt.title('Distribution by Created Time', fontsize = 16)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"00fe3c1ae5d1b375de4d9c4579b49eadbedff940"},"cell_type":"code","source":"def lat_long(l):\n    '''For latitude and longtitude, delete outlier and normalize.'''\n    l = l.loc[l['latitude']<40.95, :]\n    l = l.loc[l['latitude']>40.55, :]\n    l = l.loc[l['longitude']<-73.80, :]\n    l = l.loc[l['longitude']>-74.05, :]\n    l['latitude'] = preprocessing.scale(l['latitude'])\n    l['longitude'] = preprocessing.scale(l['longitude'])\n    return l\n\ndf_original = lat_long(df_original)\n\nhigh = df_original.loc[df_original['interest_level']=='high', :]\nmedium = df_original.loc[df_original['interest_level']=='medium', :]\nlow = df_original.loc[df_original['interest_level']=='low', :]\n\nplt.figure(figsize=(17,3.5))\n\nplt.subplot(131)\nplt.scatter(high['longitude'], high['latitude'], 5, c='blue', label='high')\nplt.title('high')\n\nplt.subplot(132)\nplt.scatter(medium['longitude'], medium['latitude'], 5, c='red', label='medium')\nplt.title('medium')\n\nplt.subplot(133)\nplt.scatter(low['longitude'], low['latitude'], 5, c='orange', label='low')\nplt.title('low')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"91a899632e1a38fcfc02884171e24e6a7bce268a","scrolled":true},"cell_type":"code","source":"df_original['Features List'] = df_original['features'].apply(lambda y : list(map(lambda x: x.upper().translate(table), y)))\ndf_original['Features String'] = df_original['Features List'].apply(' '.join)\nbiglist = ' '.join(df_original['Features String'])\n\nfrom wordcloud import WordCloud\n\nwordcloud = WordCloud( background_color='white',collocations=True).generate(biglist)\nplt.figure(figsize=(10, 6))\nplt.imshow(wordcloud, interpolation=\"bilinear\")\nplt.axis('off')\nplt.title('Key Words in Features', fontsize=16, y=1.05)\nplt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}